{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df692e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-11-27 18:45:32,625] A new study created in memory with name: no-name-ba731302-2222-42fd-a14a-bb198cbdec06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Engineering features...\n",
      "Starting Optuna optimization (this may take longer due to SVM complexity)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-27 18:45:41,778] Trial 0 finished with value: 0.5344689087238951 and parameters: {'kernel': 'rbf', 'C': 0.04839981001041211, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.5344689087238951.\n",
      "[I 2025-11-27 18:45:45,518] Trial 1 finished with value: 0.5608570473856814 and parameters: {'kernel': 'poly', 'C': 31.81055504611549, 'gamma': 'scale', 'class_weight': None, 'degree': 3}. Best is trial 1 with value: 0.5608570473856814.\n",
      "[I 2025-11-27 18:45:54,337] Trial 2 finished with value: 0.11600634060110776 and parameters: {'kernel': 'rbf', 'C': 0.001062894834292721, 'gamma': 'scale', 'class_weight': 'balanced'}. Best is trial 1 with value: 0.5608570473856814.\n",
      "[I 2025-11-27 18:45:58,902] Trial 3 finished with value: 0.38906496855564154 and parameters: {'kernel': 'poly', 'C': 0.2895343009187311, 'gamma': 'auto', 'class_weight': None, 'degree': 4}. Best is trial 1 with value: 0.5608570473856814.\n",
      "[I 2025-11-27 18:46:03,067] Trial 4 finished with value: 0.42693841069705357 and parameters: {'kernel': 'poly', 'C': 0.07403390807376685, 'gamma': 'scale', 'class_weight': None, 'degree': 4}. Best is trial 1 with value: 0.5608570473856814.\n",
      "[I 2025-11-27 18:46:07,018] Trial 5 finished with value: 0.6876316382477062 and parameters: {'kernel': 'poly', 'C': 0.5571107395354301, 'gamma': 'scale', 'class_weight': None, 'degree': 3}. Best is trial 5 with value: 0.6876316382477062.\n",
      "[I 2025-11-27 18:46:15,569] Trial 6 finished with value: 0.643977255939962 and parameters: {'kernel': 'rbf', 'C': 0.6109057845264496, 'gamma': 'scale', 'class_weight': 'balanced'}. Best is trial 5 with value: 0.6876316382477062.\n",
      "[I 2025-11-27 18:46:18,100] Trial 7 finished with value: 0.5408105647649347 and parameters: {'kernel': 'linear', 'C': 21.210044959714924, 'gamma': 'scale', 'class_weight': None}. Best is trial 5 with value: 0.6876316382477062.\n",
      "[I 2025-11-27 18:46:21,320] Trial 8 finished with value: 0.7175917056323226 and parameters: {'kernel': 'linear', 'C': 0.0014609814822331597, 'gamma': 'scale', 'class_weight': None}. Best is trial 8 with value: 0.7175917056323226.\n",
      "[I 2025-11-27 18:46:28,390] Trial 9 finished with value: 0.7450880328632814 and parameters: {'kernel': 'rbf', 'C': 1.0902105201619523, 'gamma': 'scale', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:46:35,608] Trial 10 finished with value: 0.670127563662115 and parameters: {'kernel': 'rbf', 'C': 4.774084481167485, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:46:38,385] Trial 11 finished with value: 0.716799356550983 and parameters: {'kernel': 'linear', 'C': 0.0012734126622100125, 'gamma': 'scale', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:46:41,009] Trial 12 finished with value: 0.7222670568864857 and parameters: {'kernel': 'linear', 'C': 0.011971312453189484, 'gamma': 'scale', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:46:43,535] Trial 13 finished with value: 0.7252779118108182 and parameters: {'kernel': 'linear', 'C': 0.023577653438995764, 'gamma': 'scale', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:46:50,660] Trial 14 finished with value: 0.7255156485599802 and parameters: {'kernel': 'rbf', 'C': 2.246652889986822, 'gamma': 'auto', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:46:57,615] Trial 15 finished with value: 0.7315377540086239 and parameters: {'kernel': 'rbf', 'C': 4.800941470270226, 'gamma': 'auto', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:47:04,452] Trial 16 finished with value: 0.7306662472553368 and parameters: {'kernel': 'rbf', 'C': 4.43816655539627, 'gamma': 'auto', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:47:11,050] Trial 17 finished with value: 0.46480548556261647 and parameters: {'kernel': 'rbf', 'C': 56.36064999538076, 'gamma': 'auto', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:47:18,160] Trial 18 finished with value: 0.6847076269377664 and parameters: {'kernel': 'rbf', 'C': 11.044032220360789, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 9 with value: 0.7450880328632814.\n",
      "[I 2025-11-27 18:47:25,244] Trial 19 finished with value: 0.7250402315759388 and parameters: {'kernel': 'rbf', 'C': 2.0174757359561006, 'gamma': 'auto', 'class_weight': None}. Best is trial 9 with value: 0.7450880328632814.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best trial:\n",
      "  Value (Accuracy): 0.7451\n",
      "  Params: \n",
      "    kernel: rbf\n",
      "    C: 1.0902105201619523\n",
      "    gamma: scale\n",
      "    class_weight: None\n",
      "\n",
      "Retraining best model on full dataset...\n",
      "Predicting on Test set...\n",
      "Submission saved to 'submission_svm_optuna.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. Feature Engineering\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create total companions\n",
    "    df['num_females'] = df['num_females'].fillna(0)\n",
    "    df['num_males'] = df['num_males'].fillna(0)\n",
    "    df['total_people'] = df['num_females'] + df['num_males']\n",
    "    \n",
    "    # Create total stay duration\n",
    "    df['total_nights'] = df['mainland_stay_nights'] + df['island_stay_nights']\n",
    "    \n",
    "    # Interaction: Is the traveler alone?\n",
    "    df['is_alone'] = (df['total_people'] <= 1).astype(int)\n",
    "    \n",
    "    # Simplify high cardinality countries\n",
    "    top_countries = df['country'].value_counts().nlargest(15).index\n",
    "    df['country_grouped'] = df['country'].apply(lambda x: x if x in top_countries else 'Other')\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"Engineering features...\")\n",
    "train_eng = engineer_features(train)\n",
    "test_eng = engineer_features(test)\n",
    "\n",
    "# 3. Prepare X and y\n",
    "train_eng = train_eng.dropna(subset=['spend_category'])\n",
    "y = train_eng['spend_category'].astype(int)\n",
    "X = train_eng.drop(['spend_category', 'trip_id', 'country'], axis=1)\n",
    "X_test = test_eng.drop(['trip_id', 'country'], axis=1)\n",
    "\n",
    "# 4. Preprocessing Pipeline\n",
    "numeric_features = ['num_females', 'num_males', 'mainland_stay_nights', 'island_stay_nights', 'total_people', 'total_nights']\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 5. Define Optuna Objective for SVM\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    \n",
    "    # Kernel: RBF is generally the most versatile, but Linear can be good for high dimensions\n",
    "    kernel = trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly'])\n",
    "    \n",
    "    # C: Regularization parameter. Log scale exploration is standard.\n",
    "    C = trial.suggest_float('C', 1e-3, 100.0, log=True)\n",
    "    \n",
    "    # Gamma: Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
    "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    \n",
    "    # Class weight: Balanced is often critical for imbalanced data\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "\n",
    "    # Specific params for poly kernel (degree)\n",
    "    degree = 3\n",
    "    if kernel == 'poly':\n",
    "        degree = trial.suggest_int('degree', 2, 4)\n",
    "\n",
    "    # Initialize model\n",
    "    model = SVC(\n",
    "        kernel=kernel,\n",
    "        C=C,\n",
    "        gamma=gamma,\n",
    "        degree=degree,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42,\n",
    "        max_iter=2000 # Limit iterations to speed up tuning slightly, though SVM usually converges faster\n",
    "    )\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', model)])\n",
    "\n",
    "    # Cross-validation\n",
    "    # Using 3 folds for SVM tuning because it is computationally expensive compared to Logistic Regression\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "# 6. Run Optimization\n",
    "print(\"Starting Optuna optimization (this may take longer due to SVM complexity)...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "# Fewer trials for SVM because it's slower to train\n",
    "study.optimize(objective, n_trials=20) \n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (Accuracy): {trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# 7. Retrain Best Model on Full Data\n",
    "print(\"\\nRetraining best model on full dataset...\")\n",
    "\n",
    "best_params = trial.params\n",
    "degree = best_params.get('degree', 3)\n",
    "\n",
    "final_model = SVC(\n",
    "    kernel=best_params['kernel'],\n",
    "    C=best_params['C'],\n",
    "    gamma=best_params['gamma'],\n",
    "    degree=degree,\n",
    "    class_weight=best_params['class_weight'],\n",
    "    probability=True, # Enable probability for final predictions if needed later\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', final_model)])\n",
    "\n",
    "final_pipeline.fit(X, y)\n",
    "\n",
    "# 8. Predict and Save\n",
    "print(\"Predicting on Test set...\")\n",
    "test_predictions = final_pipeline.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'trip_id': test['trip_id'],\n",
    "    'spend_category': test_predictions\n",
    "})\n",
    "\n",
    "filename = 'submission_svm_optuna.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"Submission saved to '{filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
