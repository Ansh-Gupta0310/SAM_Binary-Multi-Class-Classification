{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2466224e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Configuration:\n",
      "  Neural Network: 0.4\n",
      "  Logistic Reg:   0.4\n",
      "  SVM:            0.2\n",
      "\n",
      "[1/5] Loading and Engineering Data...\n",
      "[2/5] Preprocessing...\n",
      "\n",
      "[3/5] Training Neural Network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NN Validation Accuracy: 0.88854\n",
      "\n",
      "[4/5] Training Logistic Regression...\n",
      "  LogReg Validation Accuracy: 0.88785\n",
      "\n",
      "[5/5] Training SVM (Calibrated)...\n",
      "  SVM Validation Accuracy: 0.88658\n",
      "\n",
      "--- Calculating Weighted Ensemble ---\n",
      "Ensemble Validation Accuracy: 0.88751\n",
      "\n",
      "Success! Saved to 'submission_weighted_ensemble.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# ==============================================================================\n",
    "#  HARDCODED WEIGHTS (CHANGE THESE TO TUNE)\n",
    "# ==============================================================================\n",
    "# The sum should ideally be 1.0, but the code handles it regardless.\n",
    "# Since NN and LogReg gave slightly better scores (0.887), we give them more weight.\n",
    "WEIGHT_NN  = 0.40\n",
    "WEIGHT_LR  = 0.40\n",
    "WEIGHT_SVM = 0.20\n",
    "\n",
    "print(f\"Ensemble Configuration:\")\n",
    "print(f\"  Neural Network: {WEIGHT_NN}\")\n",
    "print(f\"  Logistic Reg:   {WEIGHT_LR}\")\n",
    "print(f\"  SVM:            {WEIGHT_SVM}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. LOAD & FEATURE ENGINEERING\n",
    "# ==============================================================================\n",
    "print(\"\\n[1/5] Loading and Engineering Data...\")\n",
    "\n",
    "train_df = pd.read_csv('train_updated.csv')\n",
    "test_df = pd.read_csv('test_updated.csv')\n",
    "test_ids = test_df[['ProfileID']]\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['Loan_to_Income'] = df['RequestedSum'] / (df['AnnualEarnings'] + 1)\n",
    "    df['Income_Stability'] = df['AnnualEarnings'] / (df['WorkDuration'] + 1)\n",
    "    total_repay = df['RequestedSum'] * (1 + df['OfferRate'] / 100)\n",
    "    df['Monthly_Burden'] = total_repay / df['RepayPeriod']\n",
    "    df['Trust_x_Accounts'] = df['TrustMetric'] * (df['ActiveAccounts'] + 1)\n",
    "    return df\n",
    "\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)\n",
    "\n",
    "y = train_df['RiskFlag'].values\n",
    "train_X_raw = train_df.drop(['RiskFlag', 'ProfileID'], axis=1)\n",
    "test_X_raw = test_df.drop(['ProfileID'], axis=1)\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. PREPROCESSING\n",
    "# ==============================================================================\n",
    "print(\"[2/5] Preprocessing...\")\n",
    "\n",
    "cat_cols = train_X_raw.select_dtypes(include=['object']).columns\n",
    "num_cols = train_X_raw.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "X = preprocessor.fit_transform(train_X_raw)\n",
    "X_test = preprocessor.transform(test_X_raw)\n",
    "\n",
    "# Split for validation (to check if ensemble improves score)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. TRAIN MODELS\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Model A: Neural Network ---\n",
    "print(\"\\n[3/5] Training Neural Network...\")\n",
    "def build_nn():\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=(X.shape[1],)),\n",
    "        layers.Dense(256, activation='swish'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='swish'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_nn = build_nn()\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "model_nn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=1024,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=0 \n",
    ")\n",
    "# Get probabilities\n",
    "prob_nn_val = model_nn.predict(X_val, verbose=0).flatten()\n",
    "prob_nn_test = model_nn.predict(X_test, verbose=0).flatten()\n",
    "print(f\"  NN Validation Accuracy: {accuracy_score(y_val, (prob_nn_val > 0.5).astype(int)):.5f}\")\n",
    "\n",
    "\n",
    "# --- Model B: Logistic Regression ---\n",
    "print(\"\\n[4/5] Training Logistic Regression...\")\n",
    "# Uses CPU (sklearn) for simplicity and stability in ensemble\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42, solver='lbfgs')\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "prob_lr_val = model_lr.predict_proba(X_val)[:, 1]\n",
    "prob_lr_test = model_lr.predict_proba(X_test)[:, 1]\n",
    "print(f\"  LogReg Validation Accuracy: {accuracy_score(y_val, (prob_lr_val > 0.5).astype(int)):.5f}\")\n",
    "\n",
    "\n",
    "# --- Model C: SVM (Calibrated) ---\n",
    "print(\"\\n[5/5] Training SVM (Calibrated)...\")\n",
    "# LinearSVC doesn't output probabilities, so we wrap it in CalibratedClassifierCV\n",
    "linear_svc = LinearSVC(dual=False, random_state=42, C=1.0)\n",
    "model_svm = CalibratedClassifierCV(linear_svc, method='sigmoid', cv=3)\n",
    "model_svm.fit(X_train, y_train)\n",
    "\n",
    "# Get probabilities\n",
    "prob_svm_val = model_svm.predict_proba(X_val)[:, 1]\n",
    "prob_svm_test = model_svm.predict_proba(X_test)[:, 1]\n",
    "print(f\"  SVM Validation Accuracy: {accuracy_score(y_val, (prob_svm_val > 0.5).astype(int)):.5f}\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. ENSEMBLE AGGREGATION\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Calculating Weighted Ensemble ---\")\n",
    "\n",
    "# Combine Probabilities (Weighted Average)\n",
    "ensemble_prob_val = (\n",
    "    (prob_nn_val * WEIGHT_NN) + \n",
    "    (prob_lr_val * WEIGHT_LR) + \n",
    "    (prob_svm_val * WEIGHT_SVM)\n",
    ")\n",
    "\n",
    "ensemble_prob_test = (\n",
    "    (prob_nn_test * WEIGHT_NN) + \n",
    "    (prob_lr_test * WEIGHT_LR) + \n",
    "    (prob_svm_test * WEIGHT_SVM)\n",
    ")\n",
    "\n",
    "# Thresholding\n",
    "ensemble_pred_val = (ensemble_prob_val > 0.5).astype(int)\n",
    "ensemble_pred_test = (ensemble_prob_test > 0.5).astype(int)\n",
    "\n",
    "# Check if Ensemble actually helped on Validation set\n",
    "acc_ensemble = accuracy_score(y_val, ensemble_pred_val)\n",
    "print(f\"Ensemble Validation Accuracy: {acc_ensemble:.5f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. SAVE SUBMISSION\n",
    "# ==============================================================================\n",
    "submission = pd.DataFrame({\n",
    "    'ProfileID': test_ids['ProfileID'],\n",
    "    'RiskFlag': ensemble_pred_test\n",
    "})\n",
    "\n",
    "filename = 'submission_weighted_ensemble.csv'\n",
    "submission.to_csv(filename, index=False)\n",
    "print(f\"\\nSuccess! Saved to '{filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
